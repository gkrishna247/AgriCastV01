{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of x is number of samples x time steps(lookback) x number of features (type of data)\n",
    "# shape of y is number of expected outcome x number of features (type of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "def create_sequence(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, :])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "def create_pred_sequence(dataset, look_back=1):\n",
    "    X = []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        X.append(a)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# select the data\n",
    "def select_data(data, start=2016, end=2024, columns=None):\n",
    "    # convert the data to a pandas dataframe\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    # create a mask for the data\n",
    "    if columns is None:\n",
    "        mask = (data['Date'].dt.year >= start) & (data['Date'].dt.year<= end)\n",
    "    else:\n",
    "        mask = (data['Date'].dt.year >= start) & (data['Date'].dt.year<= end) & (data.columns.isin(columns))\n",
    "    # select the data\n",
    "    data = data.loc[mask]\n",
    "    # drop the date column\n",
    "    data = data.drop(columns='Date')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def create_scaler(dataset):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    return scaler, dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def create_model(dataset, look_back=1, epochs=100, batch_size=1, verbose=0):\n",
    "    X, Y = create_sequence(dataset, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    Y = np.reshape(Y, (Y.shape[0], Y.shape[1]))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(X.shape[2]))  # Assuming single feature for simplicity\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "def create_input_data(dataset, look_back=1):\n",
    "    dataset = np.array(dataset)\n",
    "    dataset = dataset[-look_back:]\n",
    "    seq = create_pred_sequence(dataset, look_back)\n",
    "    print(seq.shape)\n",
    "    np.reshape(seq, (1, seq[0].shape[0], seq[0].shape[1]))\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "def predict(model, dataset, look_back=1):\n",
    "    # take last look_back days from dataset\n",
    "    dataset = dataset[-look_back:]\n",
    "    # create input datas\n",
    "    X = create_input_data(dataset, look_back)\n",
    "    # make prediction\n",
    "    prediction = model.predict(X)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "def predict_next_days(model, dataset, look_back=1, days=1):\n",
    "    predictions = []\n",
    "    for i in range(days):\n",
    "        prediction = predict(model, dataset, look_back)\n",
    "        predictions.append(prediction)\n",
    "        dataset = np.append(dataset, prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# declare the path of the data\n",
    "path_to_data = r\"data\\cleansing\\filled\\mean_filled.csv\"\n",
    "\n",
    "# load the data\n",
    "# import pandas as pd\n",
    "data = pd.read_csv(path_to_data)\n",
    "\n",
    "# select the desired data\n",
    "req_data = select_data(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler, scaled_data = create_scaler(req_data) # scaled_data is a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "train_size = int(len(scaled_data) * 0.80)\n",
    "test_size = len(scaled_data) - train_size\n",
    "train, test = scaled_data[0:train_size], scaled_data[train_size:len(scaled_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2536, 22)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2535, 1, 22)\n",
      "(2535, 22)\n",
      "[[[0.062744   0.08675535 0.         ... 0.1292732  0.08383234 0.1611815 ]]\n",
      "\n",
      " [[0.06553263 0.13880856 0.02547575 ... 0.12640046 0.08662675 0.17992353]]\n",
      "\n",
      " [[0.06553263 0.13880856 0.02547575 ... 0.12640046 0.08662675 0.20241397]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.65923034 0.62984384 0.68201351 ... 0.72191899 0.16670659 0.06747132]]\n",
      "\n",
      " [[0.65923034 0.64256796 0.68201351 ... 0.71186441 0.16518962 0.06664668]]\n",
      "\n",
      " [[0.64500837 0.6437247  0.67771639 ... 0.7075553  0.16071856 0.06934553]]]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_sequence(train)\n",
    "# print shape of x_train and y_train\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2535, 1, 22)\n",
      "(2535, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = create_model(train, look_back=1, epochs=100, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make prediction\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_next_days\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mpredict_next_days\u001b[1;34m(model, dataset, look_back, days)\u001b[0m\n\u001b[0;32m      4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(days):\n\u001b[1;32m----> 6\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[0;32m      8\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(dataset, prediction)\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, dataset, look_back)\u001b[0m\n\u001b[0;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m-\u001b[39mlook_back:]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# create input datas\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_input_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# make prediction\u001b[39;00m\n\u001b[0;32m      8\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m, in \u001b[0;36mcreate_input_data\u001b[1;34m(dataset, look_back)\u001b[0m\n\u001b[0;32m      6\u001b[0m seq \u001b[38;5;241m=\u001b[39m create_pred_sequence(dataset, look_back)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(seq\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 8\u001b[0m np\u001b[38;5;241m.\u001b[39mreshape(seq, (\u001b[38;5;241m1\u001b[39m, \u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], seq[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "predictions = predict_next_days(model, test, look_back=1, days=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
