{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of x is number of samples x time steps(lookback) x number of features (type of data)\n",
    "# shape of y is number of expected outcome x number of features (type of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "def create_sequence(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, :])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# select the data\n",
    "def select_data(data, start=2016, end=2024, columns=None):\n",
    "    # convert the data to a pandas dataframe\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    # create a mask for the data\n",
    "    if columns is None:\n",
    "        mask = (data['Date'].dt.year >= start) & (data['Date'].dt.year<= end)\n",
    "    else:\n",
    "        mask = (data['Date'].dt.year >= start) & (data['Date'].dt.year<= end) & (data.columns.isin(columns))\n",
    "    # select the data\n",
    "    data = data.loc[mask]\n",
    "    # drop the date column\n",
    "    data = data.drop(columns='Date')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def create_scaler(dataset):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    return scaler, dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def create_model(dataset, look_back=1, epochs=100, batch_size=1, verbose=1):\n",
    "    X, Y = create_sequence(dataset, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    Y = np.reshape(Y, (Y.shape[0], Y.shape[1]))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(X.shape[2]))  # Assuming single feature for simplicity\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_data(dataset, look_back=1):\n",
    "    X = []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :]\n",
    "        X.append(a)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# declare the path of the data\n",
    "path_to_data = r\"data\\cleansing\\filled\\mean_filled.csv\"\n",
    "\n",
    "# load the data\n",
    "# import pandas as pd\n",
    "data = pd.read_csv(path_to_data)\n",
    "\n",
    "# select the desired data\n",
    "req_data = select_data(data=data, start=2023, end=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler, scaled_data = create_scaler(req_data) # scaled_data is a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "train_size = int(len(scaled_data) * 0.80)\n",
    "test_size = len(scaled_data) - train_size\n",
    "train, test = scaled_data[0:train_size], scaled_data[train_size:len(scaled_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491, 22)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = create_model(train, look_back=1, epochs=100, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "input_data = create_input_data(test, look_back=7)\n",
    "prediction=model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date   Rice  Wheat  Atta (Wheat)  Gram Dal  Tur/Arhar Dal  \\\n",
      "0    2016-01-01  29.50  30.50         26.67     70.50         155.00   \n",
      "1    2016-01-02  29.60  31.40         27.50     71.40         154.60   \n",
      "2    2016-01-03  29.60  31.40         27.50     71.40         154.00   \n",
      "3    2016-01-04  29.60  31.40         27.50     71.40         151.60   \n",
      "4    2016-01-05  29.50  31.75         27.50     71.75         151.50   \n",
      "...         ...    ...    ...           ...       ...            ...   \n",
      "3166 2024-09-01  56.12  44.88         52.88     99.76         172.82   \n",
      "3167 2024-09-02  57.31  45.73         54.06     99.75         173.53   \n",
      "3168 2024-09-03  57.53  45.80         54.75     99.88         172.23   \n",
      "3169 2024-09-04  57.29  45.79         55.19     99.48         172.30   \n",
      "3170 2024-09-05  57.47  45.64         53.77    100.30         173.54   \n",
      "\n",
      "      Urad Dal  Moong Dal  Masoor Dal  Sugar  ...  Vanaspati (Packed)  \\\n",
      "0       160.00     105.75       90.00  32.75  ...               79.25   \n",
      "1       161.20     108.20       92.50  33.00  ...               82.00   \n",
      "2       161.20     108.20       92.50  33.00  ...               82.00   \n",
      "3       160.20     107.20       90.50  34.40  ...               82.00   \n",
      "4       161.50     107.50       90.50  34.25  ...               80.25   \n",
      "...        ...        ...         ...    ...  ...                 ...   \n",
      "3166    137.65     120.76       89.47  44.18  ...              126.29   \n",
      "3167    139.00     122.47       92.17  44.28  ...              126.69   \n",
      "3168    138.19     121.97       91.96  44.22  ...              126.38   \n",
      "3169    138.90     122.03       92.26  44.19  ...              127.16   \n",
      "3170    139.57     122.27       92.41  44.20  ...              127.37   \n",
      "\n",
      "      Soya Oil (Packed)  Sunflower Oil (Packed)  Palm Oil (Packed)    Gur  \\\n",
      "0             88.000000                   92.25              59.25  43.00   \n",
      "1             88.000000                   92.00              59.00  45.00   \n",
      "2             88.000000                   92.00              59.00  45.00   \n",
      "3             88.000000                   92.00              59.00  45.00   \n",
      "4             88.000000                   91.75              58.75  45.75   \n",
      "...                 ...                     ...                ...    ...   \n",
      "3166         120.706538                  115.82              95.59  57.53   \n",
      "3167         125.605161                  116.00              95.78  57.19   \n",
      "3168         125.397419                  116.06              95.91  57.34   \n",
      "3169         125.459032                  116.16              95.97  56.84   \n",
      "3170         125.307419                  116.40              96.73  57.53   \n",
      "\n",
      "      Tea Loose  Salt Pack (Iodised)  Potato  Onion  Tomato  \n",
      "0        215.00                16.25   20.50  23.25   29.50  \n",
      "1        216.00                16.60   20.40  23.60   32.00  \n",
      "2        216.00                16.60   20.40  23.60   35.00  \n",
      "3        216.00                16.60   21.40  23.00   41.40  \n",
      "4        215.00                17.00   21.25  22.75   41.00  \n",
      "...         ...                  ...     ...    ...     ...  \n",
      "3166     286.23                24.41   49.00  53.47   23.76  \n",
      "3167     283.88                24.16   48.97  53.84   23.94  \n",
      "3168     283.96                24.19   48.88  54.41   24.53  \n",
      "3169     287.13                24.07   49.32  55.45   26.58  \n",
      "3170     284.17                24.55   49.90  56.00   27.13  \n",
      "\n",
      "[3171 rows x 23 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = make_prediction(model, data, look_back=7, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 66.521255   46.973354   60.623352  ...  73.96332    44.30353\n",
      "   -7.0007057]\n",
      " [ 66.40137    46.697002   60.780437  ...  72.98297    45.123283\n",
      "  -14.687267 ]\n",
      " [ 66.45916    46.604897   60.874443  ...  73.360435   45.93052\n",
      "  -16.456154 ]\n",
      " ...\n",
      " [ 63.774437   45.58271    58.743275  ...  83.70634    75.41007\n",
      "    6.087458 ]\n",
      " [ 63.491386   45.519745   58.85807   ...  83.29533    75.0313\n",
      "    2.889969 ]\n",
      " [ 63.282093   45.41768    58.86044   ...  82.95403    75.20582\n",
      "    2.2422278]]\n",
      "[[61.33 45.16 54.48 ... 44.03 31.03 25.55]\n",
      " [61.27 45.72 53.67 ... 44.06 31.39 24.97]\n",
      " [61.41 45.66 54.29 ... 44.06 31.65 25.68]\n",
      " ...\n",
      " [57.53 45.8  54.75 ... 48.88 54.41 24.53]\n",
      " [57.29 45.79 55.19 ... 49.32 55.45 26.58]\n",
      " [57.47 45.64 53.77 ... 49.9  56.   27.13]]\n"
     ]
    }
   ],
   "source": [
    "# inverse the scaled data\n",
    "prediction = scaler.inverse_transform(prediction)\n",
    "test = scaler.inverse_transform(test)\n",
    "\n",
    "# print the prediction\n",
    "print(prediction)\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
