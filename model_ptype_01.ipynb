{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5ncTnK8IGcE2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''data columns are: Index(['Day', 'Month', 'Year', 'States/UTs', 'Rice', 'Wheat', 'Atta (Wheat)',\n",
        "       'Gram Dal', 'Tur/Arhar Dal', 'Urad Dal', 'Moong Dal', 'Masoor Dal',\n",
        "       'Sugar', 'Milk @', 'Groundnut Oil (Packed)', 'Mustard Oil (Packed)',\n",
        "       'Vanaspati (Packed)', 'Soya Oil (Packed)', 'Sunflower Oil (Packed)',\n",
        "       'Palm Oil (Packed)', 'Gur', 'Tea Loose', 'Salt Pack (Iodised)',\n",
        "       'Potato', 'Onion', 'Tomato'],\n",
        "      dtype='object')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jKzOr6xKG4Ys"
      },
      "outputs": [],
      "source": [
        "# Load the data from the CSV file\n",
        "df = pd.read_csv(r\"data\\cleansing\\filled\\data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TmhegmtXG4QW"
      },
      "outputs": [],
      "source": [
        "# Convert date columns to a datetime object\n",
        "df['Date'] = pd.to_datetime(df[['Day', 'Month', 'Year']])\n",
        "df.set_index('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pqLE05AUG4Jw"
      },
      "outputs": [],
      "source": [
        "# Select the crops for prediction\n",
        "crops = [\"Rice\", \"Wheat\", \"Atta (Wheat)\", \"Gram Dal\", \"Tur/Arhar Dal\", \"Urad Dal\", \"Moong Dal\", \"Masoor Dal\", \"Sugar\", \"Milk @\", \"Groundnut Oil (Packed)\", \"Mustard Oil (Packed)\", \"Vanaspati (Packed)\", \"Soya Oil (Packed)\", \"Sunflower Oil (Packed)\", \"Palm Oil (Packed)\", \"Gur\", \"Tea Loose\", \"Salt Pack (Iodised)\", \"Potato\", \"Onion\", \"Tomato\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(crops))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jb6B6siNG4Fo"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to store the last known data for each state\n",
        "last_known_data = {}\n",
        "for state in df['States/UTs'].unique():\n",
        "    last_known_data[state] = df[df['States/UTs'] == state].iloc[-1][crops].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K17VZZ5tG4Bh"
      },
      "outputs": [],
      "source": [
        "# Prepare data for LSTM\n",
        "data = df[crops].values\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yqTQqxoVG39I"
      },
      "outputs": [],
      "source": [
        "# Scale the data to be between 0 and 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OMsCIA9OG31R"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(scaled_data, test_size=0.2)\n",
        "#print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O4Eh9I7LG3xA"
      },
      "outputs": [],
      "source": [
        "# Create the function to create the dataset\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), :]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, :])\n",
        "    return np.array(X), np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WgrgJmkuG3s0"
      },
      "outputs": [],
      "source": [
        "# Set look_back period (number of previous days to consider)\n",
        "look_back = 7\n",
        "X_train, Y_train = create_dataset(train_data, look_back)\n",
        "X_test, Y_test = create_dataset(test_data, look_back)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lqfpnKrdG3mZ"
      },
      "outputs": [],
      "source": [
        "# Reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omUUdym3G3a-",
        "outputId": "240ae506-e6a8-4c69-fca2-a61143b7f1ae"
      },
      "outputs": [],
      "source": [
        "# Create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(X_train.shape[2]))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(X_train, Y_train, epochs=100, batch_size=1, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the model\n",
        "model.save('model02.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the scaler\n",
        "import joblib\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "01mJ3I_OH_J1"
      },
      "outputs": [],
      "source": [
        "# Scale the data to be between 0 and 1\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "last_week_data = df[crops].iloc[-7:].values \n",
        "scaled_last_week = scaler.transform(last_week_data) \n",
        "reshaped_last_week = np.reshape(scaled_last_week, (1, look_back, len(crops))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtcuDTiIH_CS",
        "outputId": "5b216073-93af-43ce-ec81-88f3860e1dfd"
      },
      "outputs": [],
      "source": [
        "# Predict\n",
        "prediction_scaled = model.predict(reshaped_last_week)\n",
        "prediction = scaler.inverse_transform(prediction_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-oaFh2_lH-5V"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame for 6/9/2024 predictions\n",
        "predictions_6_9_2024 = pd.DataFrame(data=prediction, columns=crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox9rmit_IH4q",
        "outputId": "b9c9d3eb-68c6-4ef1-c17e-5e4ab298798f"
      },
      "outputs": [],
      "source": [
        "# Predict for all states using the last known data\n",
        "for state, state_data in last_known_data.items():\n",
        "    scaled_state_data = scaler.transform(state_data.reshape(1,-1))\n",
        "    reshaped_state_data = np.reshape(scaled_state_data, (1, 1, len(crops)))\n",
        "\n",
        "    state_prediction_scaled = model.predict(reshaped_state_data)\n",
        "    state_prediction = scaler.inverse_transform(state_prediction_scaled)\n",
        "\n",
        "    predictions_6_9_2024.loc[state] = state_prediction[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3lNdgxFIHE-",
        "outputId": "d44ada5e-e011-4b03-82f2-e7f39c93e1b0"
      },
      "outputs": [],
      "source": [
        "# Display the predictions\n",
        "print(predictions_6_9_2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# --------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict for all states using a rolling window of past data\n",
        "predictions_by_state = {}  # Dictionary to store predictions for each state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for state in df['States/UTs'].unique():\n",
        "    state_data = df[df['States/UTs'] == state][crops].iloc[-look_back:].values # Last 'look_back' days of data\n",
        "    scaled_state_data = scaler.transform(state_data)\n",
        "    reshaped_state_data = np.reshape(scaled_state_data, (1, look_back, len(crops)))\n",
        "\n",
        "    state_prediction_scaled = model.predict(reshaped_state_data)\n",
        "    state_prediction = scaler.inverse_transform(state_prediction_scaled)\n",
        "    predictions_by_state[state] = state_prediction[0] # Store prediction for the state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_df = pd.DataFrame(predictions_by_state).T # Convert to DataFrame for better display\n",
        "predictions_df.columns = crops # Add column names\n",
        "print(predictions_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
